<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@400;700&display=swap" rel="stylesheet">
  <style>
      body{
        font-family: 'Raleway', sans-serif;
        line-height: 1.6;
        margin: 20px;
      }
      .button{
        text-decoration: none;
        color: #fff;
        background: #333;
        padding: 10px 15px;
        border-radius: 4px;
        transition: background 0.3s ease;
      }
      .button:hover{
        background: #555;
        transform: translateY(-5px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
      }
      code{ 
        background: #f4f4f4; 
        padding: 2px 4px; 
      }
      .section{ 
        margin-bottom: 30px;
      }
      .analogy{ 
        background: #e7f3fe; 
        border-left: 4px solid #2196F3; 
        padding: 10px; 
        margin: 10px 0; 
      }
      .example{ 
        background: #f9f9f9; 
        border: 1px solid #ddd; 
        padding: 10px; 
        margin: 10px 0; 
      }
      pre{ 
        background: #f4f4f4; 
        border: 1px solid #ccc; 
        padding: 10px; 
        overflow-x: auto; 
      }
      table{
        display: block;
        border-collapse: collapse;
        width: 80%;
        border: 1px solid #ddd;
        border-radius: 12px;
        overflow: hidden;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.05);
      }
      th, td{
        padding: 5px;
        border: 1px solid #ddd;
      }
      th{
        background-color: #f9f9f9;
        font-weight: bold;
      }
  </style>
  <title>Sequence Models</title>
</head>
<body>
  <h1>Sequence Models</h1>
  <p>This document provides a beginner-friendly introduction to Sequence Models, explaining what they are, why they are important, and how they differ from traditional machine learning models. Using simple analogies and real-life examples, it covers the core concepts behind modeling sequential data—like language, time series, and speech.</p>

  <!-- Section: Sequences -->
  <div class="section" id="sequence">
    <h2>What is a Sequence?</h2>
    <p>A sequence is an ordered list of items. In the context of machine learning and AI, these items are often data points that depend on each other in some order — like words in a sentence, stock prices over time, or audio signals.</p>
    <p>Examples:</p>
    <ul>
      <li>Sentence: "<code>I love ChatGPT</code>" — sequence of words</li>
      <li>Stock prices: Price on day 1, day 2, day 3, etc.</li>
      <li>Weather: Temperature recorded hourly</li>
    </ul>
  </div>
  <div class="analogy" id="seq_analogy">
    <strong>Imagine</strong> you have a string and you're carefully threading colorful beads onto it, one by one. Each bead you add is not random — its color and placement depend on the beads that came before it. If you suddenly put a completely different or broken bead in the middle, the whole design looks odd. In the same way, a sequence is a series where the order matters. Just like a beautiful necklace depends on the proper arrangement of beads, a sentence or a musical tune depends on the proper sequence of words or notes. You can’t just place the last bead first or skip the middle ones — every bead adds meaning step by step, just like in language, music, or time-series data where each step depends on the previous ones. This is the essence of a sequence — a meaningful pattern built one piece at a time, where the past affects the future.
  </div>

  <!-- Section: Sequence Models -->
  <div class="section" id="sequence models">
    <h2>What are Sequence Models?</h2>
    <p>Sequence models are machine learning models designed to understand, process, or generate data where the order matters.</p>
    <p>Unlike regular models that treat inputs independently, sequence models remember what came before and use that to make better predictions.</p>
    <p>They are specially built to handle sequential data, like:</p>
    <ul>
      <li>Sentences (words in order)</li>
      <li>Time-series data (stock prices, weather)</li>
      <li>Audio (sound over time)</li>
      <li>Video frames (sequence of images)</li>
    </ul>
  </div>
  <div class="section" id="importance_seq_models">
    <h2>Importance of Sequence Models</h2>
    <p>Imagine you’re watching a movie where a character is introduced, faces challenges, or experiences important events. As the story unfolds, each scene makes sense because you remember what happened before—every part depends on the order and what came earlier. Now imagine watching the same movie with scenes played randomly out of order; you’d be confused because the sequence is broken. This shows how stories—and many real-life things—happen in a sequence where the order of events matters.</p>
    <p>Similarly, if you want to predict tomorrow’s weather, just knowing today’s temperature isn’t enough. You need to consider temperatures from previous days since weather changes follow patterns over time. Sequence models are special machine learning tools designed to understand such ordered data. They capture dependencies across time or steps, using past information to make better predictions or generate meaningful results. Whether it’s predicting weather, understanding language, or analyzing stock prices, sequence models help us make sense of data that unfolds step by step.</p>
    <div class="analogy" id="conclude_seq_model_importance">
      Sequence models are crucial because they understand data where order matters. By remembering past information, they make accurate predictions and generate meaningful results in tasks like language, weather, and stock forecasting. Without them, machines can’t grasp context or sequence, making their outputs less reliable.
    </div>
    <h3>Problems with Traditional Models:</h3>
    <ol>
      <li><b>No Memory of Past Inputs:</b><br>Traditional models treat every input as independent. They don’t remember what came before. So, if you give them a sentence, they don’t understand the relationship between words.</li>
      <li><b>Ignore Order of Data:</b><br>Order matters a lot in sequences (like sentences or time-series). Traditional models don’t consider the order — they just see a bag of words or numbers, losing important context.</li>
      <li><b>Fail on Contextual Meaning:</b><br>Because they don’t remember or understand order, traditional models often give wrong predictions or outputs that don’t make sense. For example, they can’t tell the difference between “The cat chased the dog” and “The dog chased the cat.”</li>
      <li><b>Poor Performance on Time-Dependent Tasks:</b><br>Tasks like speech recognition, language translation, or stock forecasting require understanding how data evolves over time. Traditional models struggle here because they can’t capture temporal patterns.</li>
    </ol>
    <h3>Simple Examples:</h3>
    <p>Suppose you want to predict the next word after “I am going to the…”</p>
    <ul>
      <li>A traditional model might randomly guess because it doesn’t know the previous words’ context.</li>
      <li>A sequence model understands the flow and predicts something meaningful like “market” or “school.”</li>
    </ul>
    <!-- Section: table -->
    <h3>Comparison Table between Sequence model and traditional model:</h3>
    <table cellpadding="8" cellspacing="0">
      <thead>
        <tr>
          <th>Feature</th>
          <th>Traditional Models</th>
          <th>Sequence Models</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Memory of Past Inputs</strong></td>
          <td>No memory; treats inputs independently</td>
          <td>Remembers previous inputs (context)</td>
        </tr>
        <tr>
          <td><strong>Order Awareness</strong></td>
          <td>Ignores order; treats data as a bag</td>
          <td>Captures and uses the order of data</td>
        </tr>
        <tr>
          <td><strong>Context Understanding</strong></td>
          <td>Poor; can’t understand meaning from order</td>
          <td>Good; understands meaning from sequence</td>
        </tr>
        <tr>
          <td><strong>Use Case Suitability</strong></td>
          <td>Works for independent data points</td>
          <td>Designed for sequential/time-series data</td>
        </tr>
        <tr>
          <td><strong>Prediction Quality</strong></td>
          <td>Often random or irrelevant predictions</td>
          <td>Accurate, context-aware predictions</td>
        </tr>
        <tr>
          <td><strong>Example</strong></td>
          <td>Predicting next word blindly</td>
          <td>Predicting next word based on previous words</td>
        </tr>
      </tbody>
    </table>
    <h3>Explaination:</h3>
    <p>Traditional models look at each data point alone, ignoring what came before, so they miss important context and order. Sequence models, on the other hand, remember and use past information to understand patterns and make better predictions. This is why sequence models work well for things like language, speech, and time-series data where order and context are crucial.</p>
    <h2>Real Life examples of Sequence Models:</h2>
    <table cellpadding="8" cellspacing="0">
      <tr>
        <th>Example</th>
        <th>Description</th>
      </tr>
      <tr>
        <td>Google Translate</td>
        <td>Automatically translates full sentences between languages.</td>
      </tr>
      <tr>
        <td>Alexa/Siri</td>
        <td>Understands and responds to spoken commands using speech-to-text.</td>
      </tr>
      <tr>
        <td>Stock Market Prediction</td>
        <td>Forecasts stock prices by analyzing historical trends.</td>
      </tr>
      <tr>
        <td>Chatbots</td>
        <td>Generates responses in customer service chats based on user input history.</td>
      </tr>
    </table>
  </div>
  <div class="section" id="sequence_models_types">
    <h2>Types of Sequence Models</h2>
    <p>There are different types of sequence models like Autoregressive models, Markov models, Hidden Markov models, etc. We will learn about them in detail but let's have a glimpse of Autoregressive Model and Markov Model</p>
    <h3>Autoregressive Models</h3>
    <h4>What are they?</h4>
    <p>Autoregressive models are a type of sequence model where the current value depends directly on several previous values in the sequence. Think of it like predicting today’s weather by looking at the weather of the past few days, assuming the recent past influences today.</p>
    <p>Mathematically, it looks like this:</p>
    <center><b><p>X<sub>t</sub> = ϕ<sub>1</sub>X<sub>t-1</sub> + ϕ<sub>2</sub>X<sub>t-2</sub> + . . . + ϵ<sub>t</sub></p></b></center>
    <p>Here,<b> X<sub>t</sub> </b>(today's value) is predicted using past values <b></sub>X<sub>t-1</sub>, </sub>X<sub>t-2</sub>, . . .</b>, weghted by some coefficient <b>ϕ</b> plus some random noise <b>ϵ<sub>t</sub></b>.</p>
    <h4>Analogy</h4>
    <p>Imagine you’re baking a layered cake, where the flavor of the current layer depends on the flavors of the last few layers you made. Each new layer “remembers” and is influenced by the taste of previous layers. The more layers you consider, the more complex and nuanced your cake’s flavor.</p>
    <p>Similarly, an AR model predicts the current data point by “tasting” or considering a fixed number of previous points.</p>
    <h4>Use Cases:</h4>
    <ul>
      <li>Stock prices, where today’s price depends on prices in the past few days.</li>
      <li>Temperature forecasting using past days’ temperatures.</li>
      <li>Sales forecasting based on recent sales data.</li>
    </ul>
    <h4>Limitations:</h4>
    <ul>
      <li>It only looks backward a fixed number of steps; it can’t easily capture very long-term patterns or outside influences.</li>
      <li>Like a cake recipe that only tastes the last few layers, it might miss a secret ingredient added much earlier.</li>
    </ul>
    <h3>Markov Models</h3>
    <h4>What are they?</h4>
    <p>Markov models are another type of sequence model that make a strong simplification: the future depends only on the current state, not on the whole past.</p>
    <p>For example, in weather prediction, a Markov model assumes that tomorrow’s weather depends only on today’s weather, not on any earlier days.</p>
    <h3>Analogy</h3>
    <p>Think of playing a board game where your next move depends only on the current position of your piece, not how you arrived there. You decide what to do next just by looking at where you are right now, ignoring the history.</p>
    <p>This property — “the future depends only on the present” — is called the Markov property.</p>
    <h4>Use Cases:</h4>
    <ul>
      <li>Text generation where the next word depends mostly on the current word or state.</li>
      <li>Speech recognition where the current sound predicts the next sound.</li>
      <li>Simple decision processes where only the current situation matters.</li>
    </ul>
    <h4>Limitations:</h4>
    <ul>
      <li>Because it ignores history beyond the current state, it can miss important patterns that require memory of the past.</li>
      <li>Like in the board game analogy, sometimes knowing the moves you made earlier helps make better decisions, but Markov models ignore that.</li>
    </ul>
  </div>
  <div class="section" id="end">
    <P>Next up, we will learn about them ii detail!</P>
  </div>
  <a class="button" id="Button" onclick="hideTemporarily(); window.print()">Download</a>
  <a class="button" id="Button">Next -></a>
  <script>
    function hideTemporarily() {
      const element = document.getElementById("Button");
      element.style.display = "none";  // Hide the element

      // Show it again after 3 seconds (3000 milliseconds)
      setTimeout(() => {
        element.style.display = "inline-block";
      }, 2000);
    }
  </script>
</body>
</html>
